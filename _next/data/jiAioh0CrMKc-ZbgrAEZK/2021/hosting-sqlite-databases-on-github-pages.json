{"pageProps":{"post":{"filename":"2021/hosting-sqlite-databases-on-github-pages.md","frontmatter":{"csl":"../ieee-with-url.csl","date":"2021-04-17","hidden":true,"references":[],"subtitle":"(or any static file hoster)","title":"Hosting SQLite databases on Github Pages","url2cite-link-output":"sup"},"preview":"I was writing a tiny website to display statistics of how much sponsored content a Youtube creator has over time when I noticed that I often write a small tool as a website that queries some data from a database and then displays it in a graph, a table, or similar. But if you want to use a","content_ast":[{"t":"Para","c":[{"t":"Str","c":"I was writing "},{"t":"Link","c":[["",[],[["target","_blank"]]],[{"t":"Str","c":"a tiny website to display statistics of how much sponsored content a Youtube creator has over time"}],["https://phiresky.github.io/youtube-sponsorship-stats/?uploader=Adam+Ragusea",""]]},{"t":"Str","c":" when I noticed that I often write a small tool as a website that queries some data from a database and then displays it in a graph, a table, or similar. But if you want to use a database, you either need to write a backend (which you then need to host forever) or download the whole dataset into the browser (which is not so great when the dataset is more than 10MB)."}]},{"t":"Para","c":[{"t":"Str","c":"In the past when I’ve used a backend server for these small side projects at some point some external API goes down or a key wexpires or I forget about the backend and stop paying for whatever VPS it was on. Then when I revisit it years later, I’m annoyed that it’s gone and curse myself for relying on an external service (or myself caring over a longer period of time)."}]},{"t":"Para","c":[{"t":"Str","c":"Hosting a static website is much easier than a backend server - there’s many free and reliable options (like GitHub, GitLab Pages, Netlify, etc), and it scales to basically infinity without any effort."}]},{"t":"Para","c":[{"t":"Str","c":"So I wrote a tool to be able to use a real SQL database in a statically hosted website!"}]},{"t":"Para","c":[{"t":"Str","c":"Here’s a demo using the "},{"t":"Link","c":[["",[],[["target","_blank"]]],[{"t":"Str","c":"World Development Indicators dataset"}],["https://github.com/phiresky/world-development-indicators-sqlite/",""]]},{"t":"Str","c":" - a dataset with 6 tables and over 8 million rows (670 MiByte total)."}]},{"t":"CodeBlock","c":[["",["sqlite-httpvfs-demo","autorun","diffstat"],[]],"select country_code, long_name from wdi_country limit 3;"]},{"t":"Para","c":[{"t":"Str","c":"As you can see, we can query the "},{"t":"Code","c":[["",[],[]],"wdi_country"]},{"t":"Str","c":" table while fetching only 1kB of data!"}]},{"t":"Para","c":[{"t":"Str","c":"This is a full SQLite query engine. As such, we can use e.g. the "},{"t":"Link","c":[["",[],[["target","_blank"]]],[{"t":"Str","c":"SQLite JSON functions"}],["https://www.sqlite.org/json1.html",""]]},{"t":"Str","c":":"}]},{"t":"CodeBlock","c":[["",["sqlite-httpvfs-demo","autorun"],[]],"select json_extract(arr.value, '$.foo.bar') as bar\n  from json_each('[{\"foo\": {\"bar\": 123}}, {\"foo\": {\"bar\": \"baz\"}}]') as arr"]},{"t":"Para","c":[{"t":"Str","c":"We can also register JS functions so they can be called from within a query. Here’s an example with a "},{"t":"Code","c":[["",[],[]],"getFlag"]},{"t":"Str","c":" function that gets the flag emoji for a country:"}]},{"t":"CodeBlock","c":[["",["sqlite-httpvfs-demo","js","diffstat","logPageReads"],[]],"function getFlag(country_code) {\n  // just some unicode magic\n  return String.fromCodePoint(...Array.from(country_code||\"\")\n    .map(c => 127397 + c.codePointAt()));\n}\n\nawait db.create_function(\"get_flag\", getFlag)\nreturn await db.query(`\n  select long_name, get_flag(\"2-alpha_code\") as flag from wdi_country\n    where region is not null and currency_unit = 'Euro';\n`)"]},{"t":"Div","c":[["",["flex","items-center","justify-center","ph3","bg-lightest-blue","navy"],[]],[{"t":"Para","c":[{"t":"Span","c":[["",["lh-title"],[]],[{"t":"Str","c":"Press the Run button to run the following demos. You can change the code in any way you like, though if you make a query too broad it "},{"t":"Emph","c":[{"t":"Str","c":"will"}]},{"t":"Str","c":" fetch large amounts of data ;)"}]]}]}]]},{"t":"Para","c":[{"t":"Str","c":"Note that this website is 100% hosted on a static file hoster (GitHub Pages)."}]},{"t":"Para","c":[{"t":"Str","c":"So how do you use a database on a static file hoster? Firstly, SQLite is compiled to WebAssembly. SQLite can be compiled with EMScripten without any modifications, and the "},{"t":"Link","c":[["",[],[]],[{"t":"Str","c":"sql.js"}],["https://github.com/sql-js/sql.js/",""]]},{"t":"Str","c":" library is a thin JS wrapper around the wasm code."}]},{"t":"Para","c":[{"t":"Str","c":"sql.js only allows you to create and read from databases that are fully in memory though - so I implemented a virtual file system that fetches chunks of the database with HTTP Range requests when SQLite tries to read from the filesystem. From SQLite’s perspective, it just looks like it’s living on a normal computer with an empty filesystem except for a file called "},{"t":"Code","c":[["",[],[]],"/wdi.sqlite3"]},{"t":"Str","c":" that it can read from."}]},{"t":"Para","c":[{"t":"Str","c":"Since fetching data via HTTP has a pretty large overhead, we need to fetch data in chunks and find some balance between the number of requests and the used bandwidth. Thankfully, SQLite already organizes its database in "},{"t":"Quoted","c":[{"t":"DoubleQuote"},[{"t":"Str","c":"pages"}]]},{"t":"Str","c":" with a user-defined "},{"t":"Link","c":[["",[],[]],[{"t":"Str","c":"page size"}],["https://www.sqlite.org/pgszchng2016.html",""]]},{"t":"Str","c":" (4 KiB by default). I’ve set the page size to 1 KiB for this database."}]},{"t":"Para","c":[{"t":"Str","c":"Here’s an example of a simple index lookup query:"}]},{"t":"CodeBlock","c":[["",["sqlite-httpvfs-demo","diffstat","logPageReads","defaultPageReadTable"],[]],"select indicator_code, long_definition from wdi_series where indicator_name\n    = 'Literacy rate, youth total (% of people ages 15-24)'"]},{"t":"Para","c":[{"t":"Str","c":"Run the above query and look at the page read log. SQLite does 7 page reads for that query."}]},{"t":"BulletList","c":[[{"t":"Plain","c":[{"t":"Str","c":"Three page reads are just some to get some schema information (these are already cached)"}]}],[{"t":"Plain","c":[{"t":"Str","c":"Two page reads are the index lookup in the index "},{"t":"Code","c":[["",[],[]],"on wdi_series (indicator_name)"]}]}],[{"t":"Plain","c":[{"t":"Str","c":"Two page reads are on the "},{"t":"Code","c":[["",[],[]],"wdi_series"]},{"t":"Str","c":" table data."}]}]]},{"t":"Para","c":[{"t":"Str","c":"Both the index as well as the table reads are B-Tree lookups."}]},{"t":"Para","c":[{"t":"Str","c":"A more complex query: What are the countries with the lowest youth literacy rate, based on the newest data from after 2010?"}]},{"t":"CodeBlock","c":[["",["sqlite-httpvfs-demo","diffstat","logPageReads"],[]],"with newest_datapoints as (\n  select country_code, indicator_code, max(year) as year from wdi_data\n  join wdi_series using (indicator_code)\n  where\n    indicator_name = 'Literacy rate, youth total (% of people ages 15-24)'\n    and year > 2010\n  group by country_code\n)\nselect c.short_name as country, printf('%.1f %%', value) as \"Youth Literacy Rate\"\nfrom wdi_data\n  join wdi_country c using (country_code)\n  join newest_datapoints using (indicator_code, country_code, year)\norder by value asc limit 10"]},{"t":"Para","c":[{"t":"Str","c":"The above query should do around 20 GET requests, fetching a total of 270KiB. Note that it only has to do 20 requests and not 270 (as would be expected when fetching 1KiB at a time). That’s because I implemented a pre-fetching system that tries to detect access patterns through three separate virtual read heads and exponentially increases the request size for sequential reads. This means that index scans or table scans reading more than a few KiB of data will only cause a number of requests that is logarithmic in the total byte length of the scan. You can see the effect of this by looking at the "},{"t":"Quoted","c":[{"t":"DoubleQuote"},[{"t":"Str","c":"Access pattern"}]]},{"t":"Str","c":" column in the page read log above."}]},{"t":"Para","c":[{"t":"Str","c":"We can also make use of the SQLite "},{"t":"Link","c":[["",[],[]],[{"t":"Str","c":"FTS"}],["https://sqlite.org/fts5.html",""]]},{"t":"Str","c":" module so we can do a full-text search on the more text-heavy information in the database - in this case there are over 1000 human development indicators in the database with longer descriptions."}]},{"t":"CodeBlock","c":[["",["sqlite-httpvfs-demo","diffstat","logPageReads"],[]],"select * from indicator_search\nwhere indicator_search match 'educatio* femal*'\norder by rank limit 10"]},{"t":"Para","c":[{"t":"Str","c":"The total amount of data in the "},{"t":"Code","c":[["",[],[]],"indicator_search"]},{"t":"Str","c":" FTS table is around 8 MByte. The above query should only fetch around 70 KiB. You can see how it is constructed "},{"t":"Link","c":[["",[],[]],[{"t":"Str","c":"here"}],["https://github.com/phiresky/world-development-indicators-sqlite/blob/gh-pages/postproc.sh#L15",""]]},{"t":"Str","c":"."}]},{"t":"CodeBlock","c":[["",["sqlite-httpvfs-demo","ftsDemo"],[]],""]},{"t":"HorizontalRule"},{"t":"Para","c":[{"t":"Str","c":"Bonus: Since we’re already running a database in our browser, why not pretend our browser is a database?"}]},{"t":"CodeBlock","c":[["",["sqlite-httpvfs-demo"],[]],"select count(*) as number_of_demos from dom\n  where selector match '.content div.sqlite-httpvfs-demo';\nselect count(*) as sqlite_mentions from dom\n  where selector match '.content p' and textContent like '%SQLite%';"]},{"t":"Para","c":[{"t":"Str","c":"We can even insert elements directly into the DOM:"}]},{"t":"CodeBlock","c":[["",["sqlite-httpvfs-demo"],[]],"insert into dom (parent, tagName, textContent)\n    select 'ul#outtable1', 'li', short_name\n    from wdi_country where currency_unit = 'Euro'"]},{"t":"Para","c":[{"t":"Str","c":"Output:"}]},{"t":"RawBlock","c":["html","<ul id=\"outtable1\">"]},{"t":"RawBlock","c":["html","</ul>"]},{"t":"Para","c":[{"t":"Str","c":"And update elements in the DOM:"}]},{"t":"CodeBlock","c":[["",["sqlite-httpvfs-demo"],[]],"update dom set textContent =\n  get_flag(\"2-alpha_code\") || textContent\nfrom wdi_country\nwhere selector match 'ul#outtable1 > li'\n  and textContent = wdi_country.short_name"]}],"default":{"filename":"2021/hosting-sqlite-databases-on-github-pages.md","frontmatter":{"csl":"../ieee-with-url.csl","date":"2021-04-17","hidden":true,"references":[],"subtitle":"(or any static file hoster)","title":"Hosting SQLite databases on Github Pages","url2cite-link-output":"sup"},"preview":"I was writing a tiny website to display statistics of how much sponsored content a Youtube creator has over time when I noticed that I often write a small tool as a website that queries some data from a database and then displays it in a graph, a table, or similar. But if you want to use a","content_ast":[{"t":"Para","c":[{"t":"Str","c":"I was writing "},{"t":"Link","c":[["",[],[["target","_blank"]]],[{"t":"Str","c":"a tiny website to display statistics of how much sponsored content a Youtube creator has over time"}],["https://phiresky.github.io/youtube-sponsorship-stats/?uploader=Adam+Ragusea",""]]},{"t":"Str","c":" when I noticed that I often write a small tool as a website that queries some data from a database and then displays it in a graph, a table, or similar. But if you want to use a database, you either need to write a backend (which you then need to host forever) or download the whole dataset into the browser (which is not so great when the dataset is more than 10MB)."}]},{"t":"Para","c":[{"t":"Str","c":"In the past when I’ve used a backend server for these small side projects at some point some external API goes down or a key wexpires or I forget about the backend and stop paying for whatever VPS it was on. Then when I revisit it years later, I’m annoyed that it’s gone and curse myself for relying on an external service (or myself caring over a longer period of time)."}]},{"t":"Para","c":[{"t":"Str","c":"Hosting a static website is much easier than a backend server - there’s many free and reliable options (like GitHub, GitLab Pages, Netlify, etc), and it scales to basically infinity without any effort."}]},{"t":"Para","c":[{"t":"Str","c":"So I wrote a tool to be able to use a real SQL database in a statically hosted website!"}]},{"t":"Para","c":[{"t":"Str","c":"Here’s a demo using the "},{"t":"Link","c":[["",[],[["target","_blank"]]],[{"t":"Str","c":"World Development Indicators dataset"}],["https://github.com/phiresky/world-development-indicators-sqlite/",""]]},{"t":"Str","c":" - a dataset with 6 tables and over 8 million rows (670 MiByte total)."}]},{"t":"CodeBlock","c":[["",["sqlite-httpvfs-demo","autorun","diffstat"],[]],"select country_code, long_name from wdi_country limit 3;"]},{"t":"Para","c":[{"t":"Str","c":"As you can see, we can query the "},{"t":"Code","c":[["",[],[]],"wdi_country"]},{"t":"Str","c":" table while fetching only 1kB of data!"}]},{"t":"Para","c":[{"t":"Str","c":"This is a full SQLite query engine. As such, we can use e.g. the "},{"t":"Link","c":[["",[],[["target","_blank"]]],[{"t":"Str","c":"SQLite JSON functions"}],["https://www.sqlite.org/json1.html",""]]},{"t":"Str","c":":"}]},{"t":"CodeBlock","c":[["",["sqlite-httpvfs-demo","autorun"],[]],"select json_extract(arr.value, '$.foo.bar') as bar\n  from json_each('[{\"foo\": {\"bar\": 123}}, {\"foo\": {\"bar\": \"baz\"}}]') as arr"]},{"t":"Para","c":[{"t":"Str","c":"We can also register JS functions so they can be called from within a query. Here’s an example with a "},{"t":"Code","c":[["",[],[]],"getFlag"]},{"t":"Str","c":" function that gets the flag emoji for a country:"}]},{"t":"CodeBlock","c":[["",["sqlite-httpvfs-demo","js","diffstat","logPageReads"],[]],"function getFlag(country_code) {\n  // just some unicode magic\n  return String.fromCodePoint(...Array.from(country_code||\"\")\n    .map(c => 127397 + c.codePointAt()));\n}\n\nawait db.create_function(\"get_flag\", getFlag)\nreturn await db.query(`\n  select long_name, get_flag(\"2-alpha_code\") as flag from wdi_country\n    where region is not null and currency_unit = 'Euro';\n`)"]},{"t":"Div","c":[["",["flex","items-center","justify-center","ph3","bg-lightest-blue","navy"],[]],[{"t":"Para","c":[{"t":"Span","c":[["",["lh-title"],[]],[{"t":"Str","c":"Press the Run button to run the following demos. You can change the code in any way you like, though if you make a query too broad it "},{"t":"Emph","c":[{"t":"Str","c":"will"}]},{"t":"Str","c":" fetch large amounts of data ;)"}]]}]}]]},{"t":"Para","c":[{"t":"Str","c":"Note that this website is 100% hosted on a static file hoster (GitHub Pages)."}]},{"t":"Para","c":[{"t":"Str","c":"So how do you use a database on a static file hoster? Firstly, SQLite is compiled to WebAssembly. SQLite can be compiled with EMScripten without any modifications, and the "},{"t":"Link","c":[["",[],[]],[{"t":"Str","c":"sql.js"}],["https://github.com/sql-js/sql.js/",""]]},{"t":"Str","c":" library is a thin JS wrapper around the wasm code."}]},{"t":"Para","c":[{"t":"Str","c":"sql.js only allows you to create and read from databases that are fully in memory though - so I implemented a virtual file system that fetches chunks of the database with HTTP Range requests when SQLite tries to read from the filesystem. From SQLite’s perspective, it just looks like it’s living on a normal computer with an empty filesystem except for a file called "},{"t":"Code","c":[["",[],[]],"/wdi.sqlite3"]},{"t":"Str","c":" that it can read from."}]},{"t":"Para","c":[{"t":"Str","c":"Since fetching data via HTTP has a pretty large overhead, we need to fetch data in chunks and find some balance between the number of requests and the used bandwidth. Thankfully, SQLite already organizes its database in "},{"t":"Quoted","c":[{"t":"DoubleQuote"},[{"t":"Str","c":"pages"}]]},{"t":"Str","c":" with a user-defined "},{"t":"Link","c":[["",[],[]],[{"t":"Str","c":"page size"}],["https://www.sqlite.org/pgszchng2016.html",""]]},{"t":"Str","c":" (4 KiB by default). I’ve set the page size to 1 KiB for this database."}]},{"t":"Para","c":[{"t":"Str","c":"Here’s an example of a simple index lookup query:"}]},{"t":"CodeBlock","c":[["",["sqlite-httpvfs-demo","diffstat","logPageReads","defaultPageReadTable"],[]],"select indicator_code, long_definition from wdi_series where indicator_name\n    = 'Literacy rate, youth total (% of people ages 15-24)'"]},{"t":"Para","c":[{"t":"Str","c":"Run the above query and look at the page read log. SQLite does 7 page reads for that query."}]},{"t":"BulletList","c":[[{"t":"Plain","c":[{"t":"Str","c":"Three page reads are just some to get some schema information (these are already cached)"}]}],[{"t":"Plain","c":[{"t":"Str","c":"Two page reads are the index lookup in the index "},{"t":"Code","c":[["",[],[]],"on wdi_series (indicator_name)"]}]}],[{"t":"Plain","c":[{"t":"Str","c":"Two page reads are on the "},{"t":"Code","c":[["",[],[]],"wdi_series"]},{"t":"Str","c":" table data."}]}]]},{"t":"Para","c":[{"t":"Str","c":"Both the index as well as the table reads are B-Tree lookups."}]},{"t":"Para","c":[{"t":"Str","c":"A more complex query: What are the countries with the lowest youth literacy rate, based on the newest data from after 2010?"}]},{"t":"CodeBlock","c":[["",["sqlite-httpvfs-demo","diffstat","logPageReads"],[]],"with newest_datapoints as (\n  select country_code, indicator_code, max(year) as year from wdi_data\n  join wdi_series using (indicator_code)\n  where\n    indicator_name = 'Literacy rate, youth total (% of people ages 15-24)'\n    and year > 2010\n  group by country_code\n)\nselect c.short_name as country, printf('%.1f %%', value) as \"Youth Literacy Rate\"\nfrom wdi_data\n  join wdi_country c using (country_code)\n  join newest_datapoints using (indicator_code, country_code, year)\norder by value asc limit 10"]},{"t":"Para","c":[{"t":"Str","c":"The above query should do around 20 GET requests, fetching a total of 270KiB. Note that it only has to do 20 requests and not 270 (as would be expected when fetching 1KiB at a time). That’s because I implemented a pre-fetching system that tries to detect access patterns through three separate virtual read heads and exponentially increases the request size for sequential reads. This means that index scans or table scans reading more than a few KiB of data will only cause a number of requests that is logarithmic in the total byte length of the scan. You can see the effect of this by looking at the "},{"t":"Quoted","c":[{"t":"DoubleQuote"},[{"t":"Str","c":"Access pattern"}]]},{"t":"Str","c":" column in the page read log above."}]},{"t":"Para","c":[{"t":"Str","c":"We can also make use of the SQLite "},{"t":"Link","c":[["",[],[]],[{"t":"Str","c":"FTS"}],["https://sqlite.org/fts5.html",""]]},{"t":"Str","c":" module so we can do a full-text search on the more text-heavy information in the database - in this case there are over 1000 human development indicators in the database with longer descriptions."}]},{"t":"CodeBlock","c":[["",["sqlite-httpvfs-demo","diffstat","logPageReads"],[]],"select * from indicator_search\nwhere indicator_search match 'educatio* femal*'\norder by rank limit 10"]},{"t":"Para","c":[{"t":"Str","c":"The total amount of data in the "},{"t":"Code","c":[["",[],[]],"indicator_search"]},{"t":"Str","c":" FTS table is around 8 MByte. The above query should only fetch around 70 KiB. You can see how it is constructed "},{"t":"Link","c":[["",[],[]],[{"t":"Str","c":"here"}],["https://github.com/phiresky/world-development-indicators-sqlite/blob/gh-pages/postproc.sh#L15",""]]},{"t":"Str","c":"."}]},{"t":"CodeBlock","c":[["",["sqlite-httpvfs-demo","ftsDemo"],[]],""]},{"t":"HorizontalRule"},{"t":"Para","c":[{"t":"Str","c":"Bonus: Since we’re already running a database in our browser, why not pretend our browser is a database?"}]},{"t":"CodeBlock","c":[["",["sqlite-httpvfs-demo"],[]],"select count(*) as number_of_demos from dom\n  where selector match '.content div.sqlite-httpvfs-demo';\nselect count(*) as sqlite_mentions from dom\n  where selector match '.content p' and textContent like '%SQLite%';"]},{"t":"Para","c":[{"t":"Str","c":"We can even insert elements directly into the DOM:"}]},{"t":"CodeBlock","c":[["",["sqlite-httpvfs-demo"],[]],"insert into dom (parent, tagName, textContent)\n    select 'ul#outtable1', 'li', short_name\n    from wdi_country where currency_unit = 'Euro'"]},{"t":"Para","c":[{"t":"Str","c":"Output:"}]},{"t":"RawBlock","c":["html","<ul id=\"outtable1\">"]},{"t":"RawBlock","c":["html","</ul>"]},{"t":"Para","c":[{"t":"Str","c":"And update elements in the DOM:"}]},{"t":"CodeBlock","c":[["",["sqlite-httpvfs-demo"],[]],"update dom set textContent =\n  get_flag(\"2-alpha_code\") || textContent\nfrom wdi_country\nwhere selector match 'ul#outtable1 > li'\n  and textContent = wdi_country.short_name"]}]}}},"__N_SSG":true}